\documentclass[a4paper]{article}

\def\npart {IB}
\def\nterm {Michaelmas}
\def\nyear {2017}
\def\nlecturer {Geoffry Grimmet}
\def\ncourse {Markov Chains}

\include{header}

\begin{document}
\maketitle

\setcounter{section}{-1}
\section{Introduction}


Probability, An Introduction, G. Grimmett\footnote{www.statstlab.cam.ac.uk/~grg/}, D. Welsh, Chapter 12



Andrey Markov was a fine soviet Russian Mathematician in the 20th centuary. 
A random variable is actually a function

\[ X : \Omega \to S  \]

It acts on outcomes. The mathematicial formulation of an R.V. is a single function that varies randomly (eg. the number of heads in 5 flips of a coin)
The passing of time plays an essential part in the world in which we inhabit, and consequently many applications of probability involve quantities which develop randomly as time passes. Such randomly evolving processes are called \emph{random processes} or \emph{stochastic processes}, and there are many different types of these (pollen count in Cambridge, number of people entering Cindies per night).

\[ (X_{0},X_{1},X_{2},\cdots) \]


The interesting question is: are the separate events $ X_{i} $ iid, or do they depend \footnote{Dependence is a question about correlation. It is not a question about causalitiy, that's much harder.} on each other? If the distribution of $ X_{1} $ depends on $ X_{0} $ ? This essentially means probabilities factorise as products.  



Note that the use of `chain' implies we are considering discrete time. For continuous time,

\[ (X_{t}, t \in \R) \]

these are fundamentally a much more complicated object.


The \emph{general theory} of stochastic processes is much more challenging; there are too many to extract a general mathematical theory for now, so we must add a condition, such that we can extract a theory that has applications and is useful. 

There are many types of conditions; there's a lot of juice to get out of the `independence assumption' but we're throwing too much away with that. So we assume the Markov condition; loosely, all the information required to calculated the probabilities of the future is contained right now\footnote{Eckhart Tolle, Power of Now}.


\subsection{Random Walks}

In this section we consider the simplest type of random walk, where both space and time are \emph{discrete}. We shall observe the particles position at each of the discrete time points $ 0,1,2,\cdots$ and we assume that at each of these times the particle is located at one of the integer positions $ \cdots,-2,-1,0,1,2,\cdots $ of the real line. The particle moves in the following way: if $ S_{N} $ denotes the location of the particle at time $ n $, then

\[ S_{n} = \begin{cases} S_{n} + 1  & \text{ with probability } p, \\ S_{n} - 1 & \text{ with probability } q, \end{cases} \]

and we suppose that the random direction of each jump is independent of all earlier jumps. Therefore,

\[ S_{n} = S_{0} + X_{1} + X_{2} + \cdots + X_{n} \qquad \text{for } n = 0,1,2,\cdots \]

where $ S_{0} $ is the starting position and $ X_{1} ,X_{2},\cdots$ are independent random variables, with

\[ X_{i} = \begin{cases} 1  & \text{ with probability } p \\ -1 & \text{ with probability } q \end{cases} \]

We call the process $ S_{0},S_{1},\cdots $ a \emph{simple random walk}.

\begin{defi}
	If $ p = q = \frac{1}{2} $ is it called a \emph{symmetric random walk}, and \emph{asymmetric otherwise}.
\end{defi}


\begin{thm} 
	Let $ u_{n} = \P(S_{n} = S_{0}) $ be the probability that a simple random walk revisits its starting point at time $ n $. Then $ u_{n} = 0 $ if $ n $ is odd, and 
	
	\[ u_{2m} = \binom{2m}{m} p^{m} q^{m} \]
	
	if $ n = 2m $ is even
	
\end{thm}

\begin{proof}
	We may suppose without loss of generality that $ S_{0} = 0 $. The first part is obvious, for the second, note that
	
	\[ S_{2m} = X_{1} + X_{2} + \cdots + X_{2m} \]
	
	so that $ S_{2m} = 0 $ if and only if exactly $ m $ of the $ X_{i} $ equal $ +1 $ and exactly $ m $ equal $ -1 $. There are exactly $ \binom{2m}{m} $ ways of dividing the $ X_{i} $ into two sets of equal sizes, and the theorem follows.
\end{proof}

For more general transition probabilities, the simplest way to proceed is to note that for $ i \geq 1 $, the random variable $ \frac{1}{2} (X_{i} + 1) $ has the Bernoulli distribution with parameter $ p $, giving that $ B_{n} = \frac{1}{2}(S_{n} + n)$ has the binomial distribution with parameters $ n $ and $ p $. Hence,

\begin{align*}
\P(S_{n} = k | S_{0} = 0 )& = \P(B_{n} = \frac{1}{2}(n+k)) \\
& = \binom{n}{\frac{1}{2}(n+k)}p^{\frac{1}{2}(n+k)}q^{\frac{1}{2}(n - k)}
\end{align*} 

This is non-zero whenever $ k $ is such that $ \frac{1}{2}(n+k) $ is an integer between $ 0 $ and $ n $. The result of the previous theorem is obtained by setting $ k = 0 $.

\section{Markov Chains}

Let $ S $ be a countable set called the \emph{state space}, and let $ \mathbf{X} = (X_{n} : n \geq 0) $ be a sequence of random variables taking values in $ S $. 

\begin{defi} (1.1)
	The sequence $ \mathbf{X} $ is called a \emph{Markov Chain} if it satisfies the \emph{Markov Property}:
	
	\[ \P\left( X_{n+1}= i_{n+1} | X_{0} = i_{0},X_{1} = i_{1},\cdots,X_{n} = i_{n} \right) = \P\left(  X_{n+1} = i_{n+1} | X_{n} = i_{n} \right)  \]
	
	\[ \; \forall \;  n \geq 0, i_{0},\cdots,i_{n+1} \in S \]
\end{defi}

\begin{defi} (1.2)
	The Markov Chain $ \mathbf{X} $ is called homogeneous\footnote{Inhomogenous are more complicated, but not in a sense richer. So lets not obscure the mathematics. }\footnote{Henceforth (unless stated otherwise) all chains are assumed as homogenous.} if, $ \; \forall \; i,j \in S $, the conditional probability 
	
	\[ \P\left(  X_{n+1} = j | X_{n} = i \right)  \] does not depend on the value of $ n $.
\end{defi}




\begin{eg} Here are some examples of Markov chains
	\begin{enumerate}
		
		
		\item \emph{Random walk}\footnote{Often we will test new techniques on this simple example.}. Let $ Z_{1},Z_{2}, \cdots  $ be indep, $ \P\left( Z_{i} = \pm 1 \right) = p, 1-p $.
		$ X_{n} = Z_{1} + \cdots + Z_{n} $. 
		
		\item \emph{Branching process.} Let $ X_{n} $ be the size of the $n$ th generation. Each member of the $ n $th generate has a number of offspring that is independent of the past
	\end{enumerate}
	
\end{eg}



In order to study the behaviour of a chain over a finite/infinite\footnote{this is where the beautful maths lies!} length of time, we need to know two quantities

\begin{enumerate}
	\item the \emph{initial distribution} $ \lambda = (\lambda_{i} : i \in S) $ given by $ \lambda_{i} = \P(X_{0} = i) $
	
	\item the \emph{transition matrix} $ P = (p_{i,j}  : i,j \in S ) $ given by $ p_{i,j} = \P(X_{i} = j | X_{0} = i) $.
	
\end{enumerate}



\begin{prop} (1.3)
\begin{enumerate}
	\item The vector $ \lambda $ is a distribution in that $ \lambda_{i} \geq 0 $ for $ i \in S $, and $ \sum_{i\in S} \lambda_{i} = 1 $.
	\item $ P $ is a stochastic matrix in that $ p_{i,j} \geq 0 $ for $ i,j \in S $, and $ \sum_{j \in S} p_{i,j} = 1  $ for $ i \in S $, so that $ P $ has row sums 1.
\end{enumerate}
	
\end{prop}

\begin{proof}
	\begin{enumerate}
	\item Since $ \lambda_{i} $ is a probability, it is non-negative. Also, $ \sum_{i \in S} \lambda_{i} = \sum_{i} \P(X_{0} = i) = \P(X_{0} \in S) = 1 $
	\item Since $ p_{i,j} $ is a probability, it is non-negative. Finally, 
	
	\begin{align*}
	\sum_{j\in S} p_{i,j} & = \sum_{j \in S} \P( X_{1} = j| X_{0} = i ) \\
	& = \P(X_{1} \in S | X_{0} = i)  = 1
	\end{align*}
	\end{enumerate}
\end{proof}


Every conditional probability can be expressed in terms of absolute probabilities, and to study stochastic processes in complete generality, we need the joint mass function. The following theorem will be useful later

\begin{thm} 
	Let $ \lambda $ be a distribution (on $ S $) and $ P $ a stochastic matrix. The sequence $ X = (X_{n} : n \geq 0) $ is a Markov chain with initial distribution $ \lambda $ and transition matrix $ P $ if and only if:
	
	\[ \P\left(  X_{0} = i_{0}, X_{1} = i_{1}, \cdots, X_{n} = i_{n} \right) = \lambda_{i_{0}}p_{i_{0},i_{1}}p_{i_{1},i_{2}},\cdots,p_{i_{n-1},i_{n}} (*) \]
	
	for all $ n \geq 0 $ and $ i_{0},i_{1},\cdots,i_{n} \in S$.
\end{thm}


\begin{proof} \footnote{We're learning to drive here, to press the buttons and see what they do. There's nothing very deep in this proof, it's quite superficial.}
	Write  $ A_{k} $ for the event $ \{ X_{k} = i_{k} \} $. Then (*) can be written as 
	
	\[ \P\left(  A_{0} \cap A_{1} \cap \cdots A_{n} \right) = \lambda_{i_{0}} p_{i_{0},i_{1}} \cdots p_{i_{n-1},i_{n}}  \]
	
	
	Suppose $ X $ is a $ (\lambda,P) $ Markov chain. We prove by induction on $ n $. When $ n = 0 $, $ \P(X_{0} = i_{0}) = \lambda_{i_{0}} $.
	Suppose (*) holds for $ n < N $.
	
	\begin{align*}
	\P(A_{0} \cap \cdots \cap A_{N})& = \P(A_{0} \cap \cdots \cap A_{N}| A_{0 \cap \cdots \cap A_{N-1}}) \P(A_{0}\cap \cdots \cap A_{N-1}) \\
	& = \P(A_{N} | A_{0} \cap \cdots \cap A_{N-1}) \P(A_{0}\cap \cdots \cap A_{N-1})\\
	& =  \P(A_{N} | A_{N-1}) \lambda_{i_{0}} p_{i_{0},i_{1}},\cdots,p_{i_{N-2},i_{N-1}}
 	\end{align*}
 	
 	
 	
 	Conversely, suppose (*) holds, 
 	
 	By (*) with $ n = 0 $,
 	
 	\[ \P (X_{0} = i_{0}) = \lambda_{i_{0}} \]
 	
 	So $ X_{0} $ has pmf $ \lambda $.
 	
 	\[ \P(A_{N} | A_{0} \cap \cdots \cap A_{N}) = \frac{\P(A_{0} \cap \cdots \cap A_{n+1})}{\P(A_{0} \cap \cdots \cap A_{N})} = p_{i_{n},i_{n+1}} \]
 	
 	Hence $ X $ is a Markov chain with transition matrix $ P $
 \end{proof}



\begin{thm} (Extended Markov property)
	
	Let $ X $ be an MC, and $ n \geq 1 $. Let $ H $ be a historic-event, ie. $ H $ is given in terms of $ \{  X_{0},X_{1},\cdots,X_{N-1}\} $ and let $ F $ be a future event, ie. $ F $ given in terms of $ \{ X_{N+1},X_{N+2},\cdots \} $. Then
	
	\[ \P(F | H, X_{n} = i) = \P(F | X_{n} = i) \]
\end{thm}

\begin{proof}
	Assume $ F $ depends on only finitely many of the future variables.  \footnote{We're going to prove it for $ F $ depending on a finite set of events, rather than infinitely many.} \footnote{ $ \sum_{<n} := $ or ($>$) sum over all $ i_{0},\cdots,i_{N-1} $ contributing to $ H $ (or $ F $)}
	
	\begin{align*}
	\P(F | H,X_{n}= i) & = \frac{ \sum_{>N}  \sum_{< N} \lambda_{i_{0}}p_{i_{0},i_{1}},\cdots,p_{i_{N-1},i} p_{i,i_{N+1}} }{ \sum_{i < n} \lambda_{i_{0}}p_{i_{0},i_{1}},\cdots,p_{i_{N-1},i}}  \\
	& = \sum_{>N} p_{i,i_{N+1}} \\
	& = \P(F | X_{n} = i)
	\end{align*}
	
\end{proof}

\section{Transition probabilities}

One step transition probability: $ p_{i,j} = \P (X_{1} = j | X_{0} = i) $


$ n $-step $ p_{i,j} (n) = \P(X_{n} = j | X_{0} = i) $.

\begin{eg}
	How to compute $ n $-step transition probabilities from the one-step prob?
\end{eg}

\[ P = (p_{i,j})_{i,j \in S} \]

\[ P(n) = (p_{i,j}(n))_{i,j \in S} \]

\begin{thm} 
	\[ P(n) = P^{n} \]
\end{thm}

\begin{prop} (Chapman-Kolmogorov equations) \footnote{breaking up trajectories according to the value of $ k $}
	
	
	
	$ p_{i,j}(n+m) = \sum_{k \in S} p_{i,k} (m) p_{k,j} (n) $
\end{prop}

\begin{proof} \footnote{ $ \P(A \cap B | C)  = \P(A | B \cap C) \P(B | C)$ }
	\begin{align*}
	\P (X_{m + n} = j | X_{0} = i) & =  \sum_{k \in S} \P (X_{m + n} = j, X_{m = k} | X_{0} = i) \\
	& = \sum_{k} \P (X_{m + n} = j | X_{m} = k, X_{0} = i) \P( X_{m} = k  | X_{0} = i) \\
	& = \sum_{k}p_{i,k} (m) p_{k,j}(n) 
	\end{align*}
	
	By CK, $ P(m+n) = P(m) P(n) $.

	Hence $ P(n) = P(1)P(n-1) = \cdots P(1)^{n} = P^{n} $
\end{proof}


\begin{eg}
	$ | S | = 2 $, label them wlog $ S = \{ 1,2 \} $
	
	\[ P = \begin{pmatrix}
	1 - \alpha & \alpha \\
	\beta & 1 - \beta 
	\end{pmatrix} \]
	
	where\footnote{avoid degenerate cases} $ 0 < \alpha , \beta < 1 $ 
	
\begin{enumerate}
	\item 	Diagonalize, so
	
	$ \det ( P - \kappa I )= 0 $, roots\footnote{note that 1 is always an eigenvalue} $ \kappa_{1} = 1 $, $ \kappa_{2} = 1 - \alpha - \beta $.
	
	\[ P = U^{-1} \begin{pmatrix}
	1 & 0 \\
	0 & 1 - \alpha - \beta
	\end{pmatrix} U \] for some invertible $ U $.
	
	
	\[ P^{n} = U^{-1} \begin{pmatrix}
	1^{n} & 0 \\
	0 & (1 - \alpha - \beta)^{n}
	\end{pmatrix} U \]
	
	So $ p_{1,1}(n) = A + B(1 - \alpha - \beta)^{n} $, $ P_{1,1}(0) = 1 $, $ P_{1,1}(1) = 1 - \alpha $. Thus
	
	\[ A = \frac{\beta}{\alpha + \beta}, \qquad B = \frac{\alpha}{\alpha + \beta} \]
	
	\[ p_{1,2}(n) = 1 - P_{1,1}(n) \]
	
	\[ p_{2,1}(n),P_{2,2}(n) \quad \text{ obtained by interchanging } \alpha, \beta  \]
	
	\item by difference equations:
	Using CK,
	
	\begin{align*}
	p_{1,1}(n+1) & = \sum_{k} p_{1,k}(n) p_{k,1}(1) \\
	& = p_{1,1}(n)(1-\alpha) + p_{1,2} (n) \beta   \\
	& =  p_{1,1}(n)(1-\alpha) + (1 - p_{1,1(n)}) \beta  
	\end{align*}
	
	Thus
	
	\[ \pi_{n+1} = (1 - \alpha - \beta)\pi_{n} + \beta \]
	

	
	
	
\end{enumerate}
\end{eg}

	\section{Class structure}
	
	An important element in the theory of Markov chains is the interaction between the state space S and the transition mechanism $ P $. 
	
	Let $ X $ be a homogenous Markov chain with state space $ S $ and transition matrix $ P $. For $ i,j \in S $, we say $ i $ \emph{leads to} $ j $ if $ p_{i,j}(n) > 0 $ for some $ n \geq 1 $, write $ i \to j $.
Note: $ i \to i $. If $ i \to j $ and  $ j \to i  $, write $ i \leftrightarrow j $ and say $ i $ and $ j $ \emph{communicate}

\begin{prop} 
	$ \leftrightarrow $ is an equivalence relation
\end{prop}

\begin{proof}
	\begin{enumerate}
		\item reflexive: $ i \leftrightarrow i $ since $ p_{i,i}(0) = 1 > 0 $
		\item symmetric: if $ i \leftrightarrow j $ then $ j \leftrightarrow i $ by definition of $ \leftrightarrow $
		\item transitivity: assume $ i \leftrightarrow j $, $ j \leftrightarrow k $. Since $ i \mapsto j $, $ \exists m $ st. $ p_{i,j}(m) > 0 $, $ j \to k $, $ \exists n $ st. $ p_{j,k}(n) > 0 $,
		
		\[ p_{i,k}(m + n) = \sum_{r}  p_{i,r}(m)p_{r,k}(n)  \]
		
		(by CK)
		
		\[ \geq p_{i,j}(m) p_{j,k}(n) > 0 \]
		
		hence $ i \to k $.
		Similarly $ k \to i $, so $ i \leftrightarrow k $.
		
	\end{enumerate}
\end{proof}


$ \leftrightarrow $ has `equivalence classes', subsets of $ S $ of the from $ C_{i} = \{ j \in S : i \leftrightarrow j \} $. These $ C_{i} $ are called \emph{communicating classes}. If there is a unique equivalence class $ S $, call $ S $ (or the chain) \emph{irreducible}, which is to say $ i \leftrightarrow j $ for all $ i,j \in S $.

A subset $ C \subseteq S $ is called \emph{closed} if 

\[ i \in C, i \to j \quad \Rightarrow j \in C \]


If a singleton set $ \{ i \} $ is closed, we call $ i $ an \emph{absorbing} state.

\begin{prop} 
	$ C \subseteq S $ is closed iff
	
	\[ p_{i,j} = 0 \text{ for } i \in C, j \notin C   \qquad (*)  \]
	
\end{prop}

\begin{proof}
	Let $ C \subset S $. If $ * $ fails, $ \exists i \in C, j \notin C  $ with $ p_{i,j} > 0 $. 
	
	So $ i \to j $, and so $ C $ is not closed.
	
	Suppose $ (*) $ holds. 
	
	Let $ i \in C $, $ i \to j $. $ \exists m > 0 $, $ p_{i,j}(m) > 0 $,
	
	
	\[ p_{i,j}(m) = \sum_{x_{1},\cdots,x_{m-1} \in S} 
	p_{i,x_{1}},p_{x_{1},x_{2}},\cdots,p_{x_{n-1},j} \]
	
	
	So there exits $ x_{1},\cdots,x_{n-1} \in S $ such that $ p_{i_{1},x_{1}} p_{x_{1},x_{2}} \cdots p_{x_{m-1},j} > 0$.
	
	By (*), $ x_{1} \in C $, $ x_{2} \in C, \cdots, j \in C $ and hence $ C $ is closed. 
\end{proof}


\begin{eg}
	\[ P =  \begin{pmatrix}
		\frac{1}{2} & \frac{1}{2} & 0 & 0 & 0 & 0 \\
		0 & 0 & 1 & 0 & 0 & 0 \\
		\frac{1}{3} & 0 & 0 & \frac{1}{3} & \frac{1}{3} & 0 \\
		0 & 0 & 0 & \frac{1}{2} & \frac{1}{2} & 0 \\
		0 & 0 & 0 & 0 & 0 & 1 \\
	    0 & 0 & 0 & 0 & 1 & 0
	\end{pmatrix} \]

$ S = \{ 1,2,\cdots,6\} $


By drawing a picture, it is clear what the communicating classes are:

\[ \underbrace{\{1,2,3\},\{ 4\}}_{\text{ not closed }},\underbrace{\{ 5,6 \}}_{\text{ closed }} \] 
\end{eg}


\section{Recurrence or Transience}

\[ \P ( A | X_{0} = i) = \P_{i}(A) \]

\[ \E (Z | X_{0} = i) = \E_{i} (Z) \]
                           
\begin{defi}
	\emph{First passage time} of $ j \in S $ is 
	
	\[ T_{j} = \min \{ n\geq 1 : X_{n} = j \} \]
\end{defi}
                           
\begin{defi}               
	\emph{First-passage probabilities} are 
	                          
	\[ f_{i,j}(n) = \P_{i}(T_{j} = n) \]
\end{defi}

\begin{defi}
	$ i \in S $ is \emph{recurrent}\footnote{sometimes `persistent' is used} if $ \P_{i}(T_{i} < \infty) = 1 $, and \emph{transient} otherwise.
\end{defi}


\begin{thm} 
	$ i $ is recurrent iff $ \sum_{n \geq 0} p_{i,j}(n) = \infty$
	
	\[ P_{i,j}(s) = \sum_{n \geq 0} p_{i,j}(n)s^{n} \qquad  F_{i,j}(s) = \sum_{n \geq 0} f_{i,j}(n)s^{n} \]
	
	\[ \delta_{i,j} = p_{i,j}(0) = \begin{cases} 1  & \text{ if } i = j \\ 0 & \text{ if } i \neq j \end{cases} \]
	
	\[ f_{i,j}(0) = 0 \quad \forall i,j \]
\end{thm}



  \end{document}